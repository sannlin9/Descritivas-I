{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f5fd18f",
   "metadata": {},
   "source": [
    "# Adaboost\n",
    "\n",
    "## 1. Cite 5 diferenças entre o Random Forest e o AdaBoost\n",
    "\n",
    "O Random Forest e o AdaBoost são dois algoritmos populares de aprendizado de máquina que são usados ​​para construir modelos de classificação ou regressão. Aqui estão cinco diferenças entre eles:\n",
    "\n",
    "- **Abordagem do Ensemble**: Random Forest é um algoritmo de ensemble que constrói várias árvores de decisão independentes e as combina para produzir uma previsão final. O AdaBoost, por outro lado, é um algoritmo de boosting que constrói uma sequência de modelos fracos (por exemplo, árvores de decisão com poucos níveis) que são combinados para criar um modelo forte.\n",
    "\n",
    "- **Peso das instâncias**: No AdaBoost, cada instância de treinamento é atribuída um peso, que é ajustado a cada iteração do algoritmo com o objetivo de corrigir as predições incorretas dos modelos anteriores. No Random Forest, todas as instâncias têm o mesmo peso e cada árvore é construída com uma amostra aleatória do conjunto de treinamento.\n",
    "\n",
    "- **Seleção de features**: Random Forest seleciona um subconjunto aleatório das características do conjunto de treinamento para cada árvore, enquanto o AdaBoost usa todas as características em cada iteração.\n",
    "\n",
    "- **Sensibilidade a Outliers**: O AdaBoost é mais sensível a outliers e ruídos do que o Random Forest, pois dá maior peso às instâncias que são classificadas incorretamente pelos modelos anteriores.\n",
    "\n",
    "- **Performance**: O Random Forest é geralmente mais rápido do que o AdaBoost em grandes conjuntos de dados, pois pode ser paralelizado e cada árvore pode ser construída independentemente. Além disso, o Random Forest geralmente requer menos ajuste de hiperparâmetros do que o AdaBoost. No entanto, o AdaBoost geralmente produz modelos com melhor desempenho em conjuntos de dados menores ou mais complexos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342b97c",
   "metadata": {},
   "source": [
    "## 2. Acesse o link Scikit-learn – adaboost, leia a explicação (traduza se for preciso) e crie um jupyter notebook contendo o exemplo do AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1517c483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:07:19.886219Z",
     "start_time": "2023-04-18T01:07:17.810446Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7323e5ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:13:06.677875Z",
     "start_time": "2023-04-18T01:13:06.018638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9466666666666665"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968e530",
   "metadata": {},
   "source": [
    "## 3. Cite 5 Hyperparametros importantes no AdaBoost\n",
    "\n",
    "1. n_estimators \n",
    "2. learning_rate\n",
    "3. max_depth\n",
    "4. estimator\n",
    "5. min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdccc5f",
   "metadata": {},
   "source": [
    "## 4. GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e6ca7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T01:16:16.985391Z",
     "start_time": "2023-04-18T01:16:07.249440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor: 0.953333 utilizando: {'learning_rate': 0.0001, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# definindo o modelo:\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# definindo o grid de parametros para o modelo:\n",
    "\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "\n",
    "# definindo a pesquisa\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=grid,\n",
    "                           n_jobs=-1,\n",
    "                           cv=10,\n",
    "                           scoring='accuracy')\n",
    "\n",
    "# executando o gridsearch.\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# imprimindo os resultados.\n",
    "print(\"Melhor: %f utilizando: %s\" %\n",
    "      (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
