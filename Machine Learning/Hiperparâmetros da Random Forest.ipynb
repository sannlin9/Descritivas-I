{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86b9406",
   "metadata": {},
   "source": [
    "# Hiperparâmetros da Random Forest\n",
    "\n",
    "- n_estimators: Uma floresta aleatória é um conjunto de várias árvores de decisão, e o parâmetro n_estimators controla o número de árvores no classificador. Embora possa parecer que usar mais árvores sempre levará a um modelo mais generalizado, isso nem sempre é verdade. Aumentar o número de árvores pode aumentar a complexidade do modelo, mas não necessariamente levará ao overfitting. O valor padrão para n_estimators no scikit-learn é 100.\n",
    "\n",
    "- max_depth: Esse hiperparâmetro controla a profundidade máxima das árvores na floresta. É um dos mais importantes para aumentar a precisão do modelo. Aumentar a profundidade pode aumentar a precisão até certo ponto, mas, depois disso, pode levar ao overfitting. É importante escolher o valor de max_depth adequadamente para evitar overfitting. O valor padrão é \"None\", o que significa que os nós continuarão a se dividir até que todas as folhas sejam puras ou tenham menos amostras que min_samples_split (outro hiperparâmetro).\n",
    "\n",
    "- min_samples_split: Esse hiperparâmetro especifica o número mínimo de amostras que um nó interno deve ter para ser dividido em outros nós. Se esse valor for muito baixo, a árvore pode continuar a se dividir e levar ao overfitting. Aumentar o valor de min_samples_split pode limitar o número de divisões e ajudar a reduzir o overfitting. No entanto, não é bom aumentar o valor muito alto, pois isso pode levar a um modelo insuficiente. O valor padrão é 2.\n",
    "\n",
    "- min_samples_leaf: Esse hiperparâmetro especifica o número mínimo de amostras que um nó deve ter após a divisão. Ele ajuda a reduzir o overfitting quando o modelo tem muitos parâmetros. No entanto, um valor muito alto pode levar a um modelo insuficiente. O valor padrão é 1.\n",
    "\n",
    "- max_features: A floresta aleatória seleciona um subconjunto aleatório de recursos para encontrar a melhor divisão. max_features controla o número de recursos considerados para fazer a divisão. Pode assumir quatro valores: \"auto\", \"sqrt\", \"log2\" e \"None\". \"Auto\" e \"sqrt\" selecionam sqrt(n_features) recursos, \"log2\" seleciona log2(n_features) recursos e \"None\" usa todos os recursos.\n",
    "\n",
    "- max_leaf_nodes: Esse hiperparâmetro define um limite para o número de nós na árvore, o que ajuda a reduzir a profundidade e o overfitting. O valor padrão é \"None\", o que significa que a árvore continuará a crescer indefinidamente.\n",
    "\n",
    "- max_samples: Esse hiperparâmetro controla o número máximo de amostras usadas para treinar cada árvore na floresta.\n",
    "\n",
    "fonte: https://acervolima.com/hyperparameters-of-random-forest-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
